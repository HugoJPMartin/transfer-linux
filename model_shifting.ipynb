{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linux Transfer Learning notebook - Model Shifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to show how to do model shifting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principle is to learn the true value will knowing the estimated value from an old model, in order to pinpoint where this old model is wrong and to correct it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the 4.13 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "reg = load(\"gbt_413.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_columns = [\"GZIP-bzImage\", \"GZIP-vmlinux\", \"GZIP\", \"BZIP2-bzImage\", \"vmlinux\", \n",
    "              \"BZIP2-vmlinux\", \"BZIP2\", \"LZMA-bzImage\", \"LZMA-vmlinux\", \"LZMA\", \"XZ-bzImage\", \"XZ-vmlinux\", \"XZ\", \n",
    "              \"LZO-bzImage\", \"LZO-vmlinux\", \"LZO\", \"LZ4-bzImage\", \"LZ4-vmlinux\", \"LZ4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the columns name ordered for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"gbt_413_columns.json\",\"r\") as f:\n",
    "    gbt_413_columns = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the 4.15 version dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_415 = pd.read_pickle(\"datasets/dataset_415.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning a value to the 4.15 dataset in the columns that disappeared to make it compatible with the 4.13 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_413 = set(gbt_413_columns)\n",
    "columns_415 = set(df_415.columns.values)\n",
    "\n",
    "for c in columns_413.difference(columns_415):\n",
    "    df_415 = df_415.assign(**{c:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the value of kernel size for 4.15 data using the 4.13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for 4.15 :  20.014497458885717\n"
     ]
    }
   ],
   "source": [
    "X_test_415 = df_415[gbt_413_columns].drop(columns=size_columns+[\"cid\"], errors=\"ignore\")\n",
    "y_test_415 = df_415[\"vmlinux\"]\n",
    "\n",
    "y_pred = reg.predict(X_test_415)\n",
    "\n",
    "dfErrorsFold = pd.DataFrame({\"% error\":((y_pred - y_test_415)/y_test_415).abs()*100})\n",
    "error_415 = dfErrorsFold[\"% error\"].mean()\n",
    "print(\"MAPE for 4.15 : \", error_415)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is quite high, and no useable as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the estimated kernel size to the dataset : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415[\"estimated_vmlinux\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a training set with 5000 examples : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "shift_train_size = 5000\n",
    "shift_X_train, shift_X_test, shift_y_train, shift_y_test = train_test_split(df_415.drop(columns=size_columns+[\"cid\"], errors=\"ignore\"), df_415[\"vmlinux\"], train_size=shift_train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shifted MAPE :  6.460185613711549\n"
     ]
    }
   ],
   "source": [
    "gbt = ensemble.GradientBoostingRegressor(n_estimators=200, max_depth=6, min_samples_split=40, loss=\"huber\")\n",
    "gbt.fit(shift_X_train, shift_y_train)\n",
    "\n",
    "y_pred = gbt.predict(shift_X_test)\n",
    "\n",
    "dfErrorsFold = pd.DataFrame({\"% error\":((y_pred - shift_y_test)/shift_y_test).abs()*100})\n",
    "print(\"shifted MAPE : \", dfErrorsFold[\"% error\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this technique, and a very reduced training set, it is possible to get a very good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It allows a great increase in accuracy compared to the old model, or a new model only trained on the 5000 new examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using larger training set : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shifted MAPE :  5.952643196088162\n"
     ]
    }
   ],
   "source": [
    "shift_train_size = 10000\n",
    "shift_X_train, shift_X_test, shift_y_train, shift_y_test = train_test_split(df_415.drop(columns=size_columns+[\"cid\"], errors=\"ignore\"), df_415[\"vmlinux\"], train_size=shift_train_size)\n",
    "\n",
    "gbt = ensemble.GradientBoostingRegressor(n_estimators=200, max_depth=6, min_samples_split=40, loss=\"huber\")\n",
    "gbt.fit(shift_X_train, shift_y_train)\n",
    "\n",
    "y_pred = gbt.predict(shift_X_test)\n",
    "\n",
    "dfErrorsFold = pd.DataFrame({\"% error\":((y_pred - shift_y_test)/shift_y_test).abs()*100})\n",
    "print(\"shifted MAPE : \", dfErrorsFold[\"% error\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
