{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linux Transfer Learning notebook - Model Reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will measure how efficient is a model trained on a previous version of Linux kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_413 = pd.read_pickle(\"datasets/dataset_413.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_columns = [\"GZIP-bzImage\", \"GZIP-vmlinux\", \"GZIP\", \"BZIP2-bzImage\", \"vmlinux\", \n",
    "              \"BZIP2-vmlinux\", \"BZIP2\", \"LZMA-bzImage\", \"LZMA-vmlinux\", \"LZMA\", \"XZ-bzImage\", \"XZ-vmlinux\", \"XZ\", \n",
    "              \"LZO-bzImage\", \"LZO-vmlinux\", \"LZO\", \"LZ4-bzImage\", \"LZ4-vmlinux\", \"LZ4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models on 4.13 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into training and testing set. We will use most of the dataset (90%) for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size = 0.9\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_413.drop(columns=size_columns+[\"cid\"], errors=\"ignore\"), df_413[\"vmlinux\"], train_size=train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training some Gradient Boosting Trees on 4.13 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = []\n",
    "\n",
    "for max_depth in [10,15,20]:\n",
    "    for min_samples_split in [100,120]:\n",
    "        reg = ensemble.GradientBoostingRegressor(n_estimators=50, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "        reg.fit(X_train, y_train)\n",
    "        gbt.append(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  5.748417903686002\n",
      "MAPE :  5.806114524225892\n",
      "MAPE :  5.351033352835162\n",
      "MAPE :  5.419867125492005\n",
      "MAPE :  5.443962456613272\n",
      "MAPE :  5.463141003753506\n"
     ]
    }
   ],
   "source": [
    "for reg in gbt:\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    dfErrorsFold = pd.DataFrame({\"% error\":((y_pred - y_test)/y_test).abs()*100})\n",
    "    print(\"MAPE : \", dfErrorsFold[\"% error\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring accuracy on 4.15 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have accurate models on 4.13, let's measure their accuracy on 4.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415 = pd.read_pickle(\"datasets/dataset_415.pkl\")\n",
    "\n",
    "columns_413 = set(df_413.columns.values)\n",
    "columns_415 = set(df_415.columns.values)\n",
    "\n",
    "df_415_reduced = df_415[columns_413.intersection(columns_415)]\n",
    "\n",
    "for c in columns_413.difference(columns_415):\n",
    "    df_415_reduced = df_415_reduced.assign(**{c:1})\n",
    "    \n",
    "df_415_reduced = df_415_reduced[df_413.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_415 = df_415_reduced.drop(columns=size_columns+[\"cid\"], errors=\"ignore\")\n",
    "y_test_415 = df_415_reduced[\"vmlinux\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  19.51873457812496\n",
      "MAPE :  19.316773065449517\n",
      "MAPE :  18.009820189703913\n",
      "MAPE :  19.4311655531924\n",
      "MAPE :  20.625966250007096\n",
      "MAPE :  20.064375019742883\n"
     ]
    }
   ],
   "source": [
    "for reg in gbt:\n",
    "    y_pred = reg.predict(X_test_415)\n",
    "\n",
    "    dfErrorsFold = pd.DataFrame({\"% error\":((y_pred - y_test_415)/y_test_415).abs()*100})\n",
    "    print(\"MAPE : \", dfErrorsFold[\"% error\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With around 19% of MAPE, the drop in accuracy is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models on 4.15 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when we create models on a small subset of 4.15 dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 5000\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_415.drop(columns=size_columns+[\"cid\"], errors=\"ignore\"), df_415[\"vmlinux\"], train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  12.451274698791465\n",
      "MAPE :  12.699376904645925\n",
      "MAPE :  12.344858902143821\n",
      "MAPE :  12.703073855965528\n",
      "MAPE :  12.600435352748892\n",
      "MAPE :  12.756038524831082\n"
     ]
    }
   ],
   "source": [
    "gbt_415 = []\n",
    "\n",
    "for max_depth in [10,15,20]:\n",
    "    for min_samples_split in [100,110]:\n",
    "        reg = ensemble.GradientBoostingRegressor(n_estimators=50, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "        reg.fit(X_train, y_train)\n",
    "        gbt_415.append(reg)\n",
    "        \n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        dfErrorsFold = pd.DataFrame({\"% error\":((y_pred - y_test)/y_test).abs()*100})\n",
    "        print(\"MAPE : \", dfErrorsFold[\"% error\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  16.051866017399558\n",
      "MAPE :  16.0495295292039\n",
      "MAPE :  15.633797930375403\n",
      "MAPE :  15.731060099086475\n",
      "MAPE :  15.516226685933393\n",
      "MAPE :  15.596609010372102\n"
     ]
    }
   ],
   "source": [
    "rf_415 = []\n",
    "\n",
    "for max_depth in [10,15,20]:\n",
    "    for min_samples_split in [5,10]:\n",
    "        reg = ensemble.RandomForestRegressor(n_estimators=50, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "        reg.fit(X_train, y_train)\n",
    "        rf_415.append(reg)\n",
    "        \n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        dfErrorsFold = pd.DataFrame({\"% error\":((y_pred - y_test)/y_test).abs()*100})\n",
    "        print(\"MAPE : \", dfErrorsFold[\"% error\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that little data, error rate is still high, but better than models trained on ~85k examples from 4.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models on 4.13 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"feature_ranking_list.json\",\"r\") as f:\n",
    "    feature_ranking_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.9\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_413[feature_ranking_list[:1500]], df_413[\"vmlinux\"], train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  5.947161509251938\n",
      "MAPE :  5.91347519058521\n",
      "MAPE :  5.553199227362323\n",
      "MAPE :  5.555897257663443\n",
      "MAPE :  5.577435355690064\n",
      "MAPE :  5.5954777235625945\n"
     ]
    }
   ],
   "source": [
    "gbt_fs = []\n",
    "\n",
    "for max_depth in [10,15,20]:\n",
    "    for min_samples_split in [100,120]:\n",
    "        reg = ensemble.GradientBoostingRegressor(n_estimators=50, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "        reg.fit(X_train, y_train)\n",
    "        gbt_fs.append(reg)\n",
    "        \n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        dfErrorsFold = pd.DataFrame({\"% error\":((y_pred - y_test)/y_test).abs()*100})\n",
    "        print(\"MAPE : \", dfErrorsFold[\"% error\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring accuracy on 4.15 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_415 = df_415_reduced.drop(columns=size_columns+[\"cid\"], errors=\"ignore\")[feature_ranking_list[:1500]]\n",
    "y_test_415 = df_415_reduced[\"vmlinux\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  16.452639126911276\n",
      "MAPE :  17.17782212092812\n",
      "MAPE :  16.440303191448237\n",
      "MAPE :  15.858597758323798\n",
      "MAPE :  16.672099089470418\n",
      "MAPE :  16.94841784016877\n"
     ]
    }
   ],
   "source": [
    "for reg in gbt_fs:\n",
    "    y_pred = reg.predict(X_test_415)\n",
    "\n",
    "    dfErrorsFold = pd.DataFrame({\"% error\":((y_pred - y_test_415)/y_test_415).abs()*100})\n",
    "    print(\"MAPE : \", dfErrorsFold[\"% error\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the feature selection has a good influence on the accuracy on 4.15, but still not enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models on 4.15 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the feature selection directly on a model trained on 4.15 data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature_ranking_list_415.json\",\"r\") as f:\n",
    "    feature_ranking_list_415 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 5000\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_415[feature_ranking_list_415[:1500]], df_415[\"vmlinux\"], train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  10.906124963734033\n",
      "MAPE :  10.627949495074306\n",
      "MAPE :  10.736555720720435\n",
      "MAPE :  10.825859922426863\n",
      "MAPE :  10.719017301290679\n",
      "MAPE :  10.708744192199589\n"
     ]
    }
   ],
   "source": [
    "gbt_fs_415 = []\n",
    "\n",
    "for max_depth in [10,15,20]:\n",
    "    for min_samples_split in [100,110]:\n",
    "        reg = ensemble.GradientBoostingRegressor(n_estimators=50, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "        reg.fit(X_train, y_train)\n",
    "        gbt_fs_415.append(reg)\n",
    "        \n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        dfErrorsFold = pd.DataFrame({\"% error\":((y_pred - y_test)/y_test).abs()*100})\n",
    "        print(\"MAPE : \", dfErrorsFold[\"% error\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  14.921914512983227\n",
      "MAPE :  14.836444634379811\n",
      "MAPE :  14.086638287846917\n",
      "MAPE :  14.289549916313362\n",
      "MAPE :  14.096930755592792\n",
      "MAPE :  14.168525003760703\n"
     ]
    }
   ],
   "source": [
    "rf_fs_415 = []\n",
    "\n",
    "for max_depth in [10,15,20]:\n",
    "    for min_samples_split in [5,10]:\n",
    "        reg = ensemble.RandomForestRegressor(n_estimators=50, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "        reg.fit(X_train, y_train)\n",
    "        rf_fs_415.append(reg)\n",
    "        \n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        dfErrorsFold = pd.DataFrame({\"% error\":((y_pred - y_test)/y_test).abs()*100})\n",
    "        print(\"MAPE : \", dfErrorsFold[\"% error\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both Gradient Boosting Trees and Random Forest, feature selection makes the models gain in accuracy, and still better than simply using the 4.13 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models trained on the version 4.13 of Linux Kernel can't be used on other versions as is, the drop in accuracy is too important. Using 5k examples from version 4.15 shows better results than using 85k examples from version 4.13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
